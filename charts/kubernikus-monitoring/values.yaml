# Name of the Prometheus to which the alert and aggregation rules should be assigned to.
prometheusName: kubernikus

kube-rules:
  # Name of the Prometheus to which the rules should be assigned to.
  prometheusName: kubernikus

  # The alert tier.
  tier: kks

  # Disable alerts that are too specific to our baremetal controlplane.
  disableAlerts:
    - controlplane

allowedMetrics:
  cAdvisor:
    - container_cpu_cfs_periods_total
    - container_cpu_cfs_throttled_seconds_total
    - container_cpu_cfs_throttled_periods_total
    - container_cpu_usage_seconds_total
    - container_fs_inodes_total
    - container_fs_limit_bytes
    - container_fs_usage_bytes
    - container_last_seen
    - container_memory_usage_bytes
    - container_memory_working_set_bytes
    - container_network_receive_bytes_total
    - container_network_transmit_bytes_total

  kubelet:
    - kubelet_pod_start_latency_microseconds
    - kubelet_running_pod_count
    - process_max_fds
    - process_open_fds

  kubeAPIServer:
    - apiserver_request_count
    - apiserver_request_latencies_bucket
    - etcd_object_counts
    - process_max_fds
    - process_open_fds

prometheus-kubernikus:
  name: kubernikus

  retentionTime: 7d

  externalLabels:
    cluster_type: kubernikus-controlplane
    # Tier used for alerts.
    tier: kks

    # Defined via secrets.
    # region:
    # cluster:

  additionalScrapeConfigs:
    name: kubernikus-additional-scrape-config
    key: scrape-config.yaml

  ingress:
    enabled: true
    host: prometheus.kubernikus

    authentication:
      authTLSSecret: "kubernikus-system/ca-crt"

  persistence:
    enabled: true
    size: 300Gi

  serviceAccount:
    create: false
    name: default

  serviceDiscoveries:
    endpoints:
      enabled: false

  resources:
    requests:
      cpu: 100m
      memory: 500Mi

  alertmanagers:
    - alertmanager.eu-de-1.cloud.sap
  #  - alertmanager.eu-nl-1.cloud.sap

  # Required for prometheus-kubernikus <- prometheus-openstack federation of limes metrics.
  secrets:
    - prometheus-openstack-sso-cert

# SSO certificate required for prometheus-kubernikus <- prometheus-openstack federation of limes metrics.
authentication:
  enabled: false
  # ssoCert:
  # ssoKey:

prometheus-node-exporter:
  image:
    repository: prom/node-exporter
    tag: v0.18.1

  serviceAccount:
    create: false
    name: default

  rbac:
    create: false

  extraArgs:
    - --collector.filesystem.ignored-mount-points=\"^/(sys|proc|dev|host|etc)($|/)\"

  # set manually to empty
  tolerations: []

  extraHostVolumeMounts:
    - name: dbus
      hostPath: /var/run/dbus/system_bus_socket
      mountPath: /var/run/dbus/system_bus_socket
      readOnly: true

  resources:
    requests:
      memory: 100Mi
      cpu: 100m

kube-state-metrics:
  image:
    repository: sapcc/kube-state-metrics
    tag: v1.6.0

  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"

  rbac:
    create: false
    serviceAccountName: default

  collectors:
    # Not useful but a lot of metrics.
    configmaps: false
    secrets: false
    horizontalpodautoscalers: false

  resources:
    requests:
      memory: 150Mi
      cpu: 100m

eventexporter:
  rbac:
    create: true

  metrics:
    config:
      config.yaml: |-
        metrics:
        - name: volume_mount_error_total
          event_matcher:
          - key: InvolvedObject.Kind
            expr: Pod
          - key: Reason
            expr: (FailedAttachVolume|FailedMount)
          - key: Type
            expr: Warning
          - key: Source.Component
            expr: attachdetach.*
          labels:
            node: Object.Spec.NodeName
        - name: volume_mount_success_total
          event_matcher:
          - key: InvolvedObject.Kind
            expr: Pod
          - key: Message
            expr: MountVolume.SetUp succeeded for volume .pvc-.*
          - key: Reason
            expr: SuccessfulMountVolume
          labels:
            node: Source.Host
        - name: volume_multi_attach_error_total
          event_matcher:
          - key: InvolvedObject.Kind
            expr: Pod
          - key: Message
            expr: Multi-Attach error for volume.*
          - key: Reason
            expr: FailedAttachVolume
          labels:
            node: InvolvedObject.Name

grafana:
  image:
    repository: grafana/grafana
    tag: 6.2.4

  admin:
    existingSecret: kubernikus-monitoring-grafana-admin
    userKey: adminUser
    passwordKey: adminPassword
    # Defined via secrets.
    # username: admin-user
    # password: admin-password

  rbac:
    pspEnabled: false

  # Ingress disabled by default as hosts and tls are set via secrets.
  ingress:
    enabled: false
    annotations:
      vice-president: "true"
      prometheus.io/probe: "true"
      nginx.ingress.kubernetes.io/configuration-snippet: |
        rewrite ^/$ /dashboard/db/kubernikus?refresh=1m&orgId=1&kiosk=true redirect;
      nginx.ingress.kubernetes.io/auth-tls-secret: "kubernikus-system/ca-crt"
      nginx.ingress.kubernetes.io/auth-tls-verify-depth: "3"
      nginx.ingress.kubernetes.io/auth-tls-verify-client: "optional"

    # Defined via secrets.
    # hosts:
    #   - grafana.domain.tld
    #
    # tls:
    #  - secretName: tls-grafana-domain-tld
    #    hosts:
    #      - grafana.domain.tld

  plugins: grafana-piechart-panel,natel-discrete-panel,grafana-worldmap-panel

  # Sidecar for discovering & reloading dashboard, datasource configmaps.
  sidecar:
    dashboards:
      enabled: true
      # Label that configmaps with dashboards should have to be added.
      label: kubernikus-grafana-dashboard
      # Only search for dashboards in the specified namespace.
      searchNamespace: kubernikus-system

    datasources:
      enabled: true
      # Label that configmaps with datasources should have to be added.
      label: kubernikus-grafana-datasource
      # Only search for dashboards in the specified namespace.
      searchNamespace: kubernikus-system

  grafana.ini:
    paths:
      data: /var/lib/grafana/data
      logs: /var/log/grafana
      plugins: /var/lib/grafana/plugins
      provisioning: /var/lib/grafana/provisioning

    server:
      protocol: http
      http_addr:
      http_port: 3000
      domain: localhost
      enforce_domain: false
      root_url: "%(protocol)s://%(domain)s:%(http_port)s"
      router_logging: false
      static_root_path: public
      enable_gzip: false
      cert_file:
      cert_key:
      socket: /tmp/grafana.sock

    users:
      allow_sign_up: false
      allow_org_create: false
      auto_assign_org: true
      auto_assign_org_role: Admin
      default_theme: dark

    auth.anonymous:
      enabled: true
      org_name: Main Org.
      org_role: Admin

    auth.proxy:
      enabled: true
      header_name: X-REMOTE-USER
      header_property: username
      auto_sign_up: true

    auth.basic:
      enabled: false

    smtp:
      enabled: false

    log:
      mode: console
      level: debug

    alerting:
      enabled: false
